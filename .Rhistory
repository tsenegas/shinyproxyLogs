pattern_fatal   <- stringr::regex("fatal", ignore_case = TRUE)
pattern_info    <- stringr::regex("info|debug|started|listening|connected|released", ignore_case = TRUE)
# Read file contents and compute statistics
file_info <- file_info |>
dplyr::rowwise() |>
dplyr::mutate(
content         = list(readLines(filePath, warn = FALSE)),
numLines        = length(content),
numErrorLines   = sum(stringr::str_detect(content, pattern_error)),
numWarningLines = sum(stringr::str_detect(content, pattern_warning)),
numFatalLines   = sum(stringr::str_detect(content, pattern_fatal)),
numInfoLines    = sum(stringr::str_detect(content, pattern_info))
) |>
dplyr::ungroup() |>
dplyr::select(-content)
# Summarize statistics by container (grouping by specId, proxyId, and startupTime)
summary_df <- file_info |>
dplyr::group_by(specId, proxyId, startupTime) |>
dplyr::summarise(
stdout_lines      = sum(numLines[logType == "stdout"], na.rm = TRUE),
stderr_lines      = sum(numLines[logType == "stderr"], na.rm = TRUE),
total_error_lines = sum(numErrorLines, na.rm = TRUE),
total_warning_lines = sum(numWarningLines, na.rm = TRUE),
total_fatal_lines = sum(numFatalLines, na.rm = TRUE),
total_info_lines  = sum(numInfoLines, na.rm = TRUE),
.groups = "drop"
)
# If path_shinylogs is provided, retrieve ShinyProxy users and associated containers
if (!is.null(path_shinylogs)) {
files_identity <- list.files(path_shinylogs, full.names = TRUE)
files_identity <- files_identity[stringr::str_detect(files_identity, "\\.(log|gz)$")]
user_proxy_mapping <- purrr::map_df(files_identity, function(file) {
log_lines <- read_log_file(file)
extract_user_proxy_mapping(log_lines)
})
user_proxy_mapping <- unique(user_proxy_mapping)
summary_df <- summary_df |>
dplyr::left_join(user_proxy_mapping, by = c('proxyId', 'specId')) |>
dplyr::select(specId, proxyId, user, startupTime, stdout_lines, stderr_lines, total_error_lines, total_warning_lines, total_fatal_lines, total_info_lines)
}
list(file_info = file_info, summary = summary_df)
}
#' Read a Log File
#'
#' Internal function to read a log file, supporting both plain text and gzipped formats.
#'
#' @param file Character. The file path to read.
#' @return A character vector of log lines.
#' @keywords internal
read_log_file <- function(file) {
if (grepl("\\.gz$", file)) {
readLines(gzfile(file), warn = FALSE)
} else {
readLines(file, warn = FALSE)
}
}
#' Extract User and Proxy Mappings
#'
#' Internal function to extract user and container mappings from log lines.
#'
#' @param log_lines A character vector containing log file lines.
#' @return A tibble with `user`, `proxyId`, and `specId`.
#' @keywords internal
#' @importFrom tibble tibble
extract_user_proxy_mapping <- function(log_lines) {
pattern <- "\\[user=([^ ]+) proxyId=([^ ]+) specId=([^ ]+)\\]"
matches <- stringr::str_match(log_lines, pattern)
tibble::tibble(
user    = matches[, 2],
proxyId = matches[, 3],
specId  = matches[, 4]
) |>
dplyr::filter(!is.na(user))
}
devtools::install_github("tsenegas/shinyproxyLogs")
library(shiny); runApp('~/test.R')
runApp('~/test.R')
#' Get a Situation Report ("sitrep") on System, Internal Package Versions and Dependencies
#'
#' This function gives a quick overview of the versions of R and the operating
#' system as well as the versions of internal packages, options, and their dependencies.
#' It's primarily designed to help triage issues and identify whether the problem
#' is outdated versions or missing options/environment variables.
#'
#' Adapted from past work:
#' <https://github.com/nflverse/nflreadr/blob/main/R/utils_sitrep.R>
#'
#' @param pkg a character vector naming packages to check, defaulting to `.internal_packages()`
#'
#' @param dev_repos URLs of cran-like private repositories for the packages in
#' question, e.g. r-universe, drat type repos. This is used to identify whether
#' the installed version of internal packages are outdated.
#'
#' @return "sitrep" list object containing information about packages, that can be
#' pretty-printed via print() or converted to json via `jsonlite::toJSON()` for
#' other uses
#'
#' @examples
#' \donttest{
#'   sitrep()
#' }
#' @export
sitrep <- function(pkg = .internal_packages(), dev_repos = .dev_repos()) {
rlang::check_installed(c("data.table","cli","glue","curl"))
#' optional: force pkg to come from .internal_packages()
pkg <- rlang::arg_match(pkg, values = .internal_packages(), multiple = TRUE)
.sitrep(pkg)
}
#' list of internal packages
.internal_packages <- function() {
pkg <- c(
"nflreadr",
"nflfastR"
)
}
.dev_repos <- function(){
c("https://nflverse.r-universe.dev")
}
.sitrep <- function(pkg, dev_repos = .dev_repos()) {
out <- structure(
list(
system_info = list(),
env_vars = list(),
installed = list(),
package_options = list(),
not_installed = list(),
dependencies = list(),
packages = pkg,
timestamp = Sys.time()
),
class = c("sitrep", "list")
)
# OPERATING SYSTEM INFO
out$system_info <- list(
r_version = R.version$version.string,
os_version = utils::osVersion
)
out$env_vars <- .sitrep_env_vars()
packages <- pkg
inst_pkgs <- data.table::as.data.table(utils::installed.packages())
out$not_installed <- packages[!packages %in% inst_pkgs$Package]
packages <- packages[packages %in% inst_pkgs$Package]
if (length(packages) == 0) return(out)
out$installed <- .sitrep_pkg_status(packages = packages,
inst_pkgs = inst_pkgs,
dev_repos = dev_repos,
check_latest = TRUE)
# Relies on options for a given package being prefixed by said package name
out$package_options <- .sitrep_pkg_opts(packages)
out$dependencies <- .sitrep_pkg_deps(packages = packages,
inst_pkgs = inst_pkgs,
recursive = TRUE)
return(out)
}
.sitrep_pkg_status <- function(packages,
inst_pkgs = utils::installed.packages(),
dev_repos = .dev_repos(),
check_latest = curl::has_internet()){
inst_pkgs <- data.table::as.data.table(inst_pkgs)
Package <- Version <- NULL
inst <- inst_pkgs[Package %in% packages][, list(package = Package, installed = Version, cran = NA, dev = NA, behind = NA)]
if (!curl::has_internet() || !check_latest) return(as.data.frame(inst))
cran_repos <- c(
"https://packagemanager.posit.co/cran/latest",
"https://cloud.r-project.org",
"https://cran.rstudio.com"
)
cran_pkgs <- data.table::as.data.table(utils::available.packages(repos = cran_repos))[Package %in% packages, list(package = Package, cran = Version)]
dev_pkgs <- data.table::as.data.table(utils::available.packages(repos = dev_repos))[Package %in% packages, list(package = Package, dev = Version)]
package <- installed <- cran <- dev <- behind_cran <- behind_dev <- behind <- NULL
inst <- merge(
merge(
inst[, list(package, installed)],
cran_pkgs,
by = "package",
all = TRUE
),
dev_pkgs,
all = TRUE,
by = "package"
)[
, list(
package, installed, cran, dev,
behind_cran = ifelse(!is.na(cran), package_version(installed, strict = FALSE) < package_version(cran, strict = FALSE), FALSE),
behind_dev = ifelse(!is.na(dev), package_version(installed, strict = FALSE) < package_version(dev, strict = FALSE), FALSE)
)
][
, list(
package, installed, cran, dev,
behind = paste0(ifelse(behind_cran, "cran;", ""), ifelse(behind_dev, "dev", "")),
behind_cran = NULL,
behind_dev = NULL
)
]
return(as.data.frame(inst))
}
.sitrep_env_vars <- function(pattern = "^ZELUS|SHINYPROXY"){
env_vars <- Sys.getenv()
# Search for common prefix patterns
env_vars <- env_vars[grepl(pattern, names(env_vars), ignore.case = TRUE)]
env_vars <- env_vars[names(env_vars) != "ZELUS_ENV"]
# redact confidential tokens
token_vars <- grepl("TOKEN", names(env_vars), ignore.case = TRUE)
env_vars[token_vars] <- sapply(env_vars[token_vars], .redact_string)
return(env_vars)
}
.redact_string <- \(x) {
l <- nchar(x)
if (l <= 8) {
return("<redacted>")
}
paste0(substr(x, 1, 3), "..<redacted>..", substr(x, l - 2, l))
}
#' Show options for specified packages
#' @keywords internal
.sitrep_pkg_opts <- function(packages, redact = TRUE){
opts <- options()
pkg_search_string <- paste(packages, collapse = "|")
package_options <- opts[grepl(pkg_search_string, x = names(opts))]
return(package_options)
}
#' Show dependency versions of specified packages
#' @keywords internal
.sitrep_pkg_deps <- function(packages, inst_pkgs = utils::installed.packages(), recursive = TRUE){
inst_pkgs <- data.table::as.data.table(inst_pkgs)
.flatten <- function(x) sort(unique(unlist(x, use.names = FALSE)))
deps <- .flatten(tools::package_dependencies(packages, db = inst_pkgs, recursive = recursive))
deps <- deps[!deps %in% packages]
missing_pkgs <- setdiff(deps, inst_pkgs$Package)
dep_status <- inst_pkgs[
inst_pkgs$Package %in% deps
][
, c("Package", "Version")
][
, priority := seq_len(.N)
, by = Package
][
priority == 1
][
order(Package)
][
, priority := NULL
]
dep_status <- unique(dep_status)
data.table::setnames(dep_status, c("package","version"))
if(length(missing_pkgs) > 0) {
dep_status <- data.table::rbindlist(
list(
dep_status,
data.table::data.table(package = missing_pkgs, version = "missing")
)
)
}
return(as.data.frame(dep_status))
}
#' sitrep data class
#'
#' `sitrep()` returns an S3 class that was created to allow for custom
#' printing. It will otherwise dispatch to the `list` class.
#'
#' Re-exporting with `methods::setOldClass()` allows these dataframes to be used
#' in S4 generics like those from DBI and jsonlite.
#'
#' @name sitrep-data-class
#'
#' @exportClass sitrep
methods::setOldClass("sitrep", "list")
#' Print method for sitrep
#' @export
print.sitrep <- function(x, ...) {
cli::cat_rule(cli::style_bold("System Info"), col = cli::make_ansi_style("cyan"), line = 1)
cli::cat_bullet(glue::glue("{x$system_info$r_version} {cli::symbol$bullet} Running under: {x$system_info$os_version}")) # nolint
cli::cat_rule(cli::style_bold("Environment Variables"), col = cli::make_ansi_style("cyan"), line = 1)
.cat_options(names(x$env_vars), unname(x$env_vars))
cli::cat_rule(cli::style_bold("Package Status"), col = cli::make_ansi_style("cyan"), line = 1)
if(nrow(x$installed) > 0) {
print(x$installed)
}
cli::cat_rule(cli::style_bold("Package Options"), col = cli::make_ansi_style("cyan"), line = 1)
if (length(x$package_options) == 0) cli::cat_bullet("No options set for above packages")
if (length(x$package_options) > 0) .cat_options(names(x$package_options), unname(x$package_options))
if (length(x$dependencies) >= 1) {
cli::cat_rule(cli::style_bold("Package Dependencies"), col = cli::make_ansi_style("cyan"), line = 1)
.cat_pkg(x$dependencies$package, x$dependencies$version)
}
if (length(x$not_installed) >= 1) {
cli::cat_rule(cli::style_bold("Not Installed"), col = cli::make_ansi_style("cyan"), line = 1)
.cat_pkg(x$not_installed, rep_len("", length(x$not_installed)))
}
cli::cat_rule(col = cli::make_ansi_style("cyan"), line = 1)
return(invisible(x))
}
.cat_pkg <- function(packages, versions) {
stopifnot(length(packages) == length(versions))
if (length(packages) <= 2) {
cli::cat_bullet(glue::glue("{format(packages)} ({format(versions)})"))
return(invisible())
}
l <- length(packages)
breaks <- cut(
x = seq_along(packages),
breaks = c(0, ceiling(l / 3), 2 * ceiling(l / 3), l + 1)
)
p <- split(packages, breaks)
v <- split(versions, breaks)
r <- length(p[[1]]) - length(p[[3]])
if (r != 0) {
p[[3]] <- c(p[[3]], rep("", r))
v[[3]] <- c(v[[3]], rep("", r))
}
p <- lapply(p, function(x) ifelse(x != "", format(paste(cli::symbol$bullet, x)), ""))
v <- lapply(v, function(x) ifelse(x != "", format(paste0(" (", x, ")")), ""))
cli::cat_line(
paste0(
p[[1]], v[[1]], "  ",
p[[2]], v[[2]], "  ",
p[[3]], v[[3]], "  "
)
)
}
.cat_options <- function(option_names, option_values) {
stopifnot(length(option_names) == length(option_values))
cli::cat_bullet(glue::glue("{format(option_names)}: {format(option_values)}"))
}
siterep()
sitrep()
sitrep()
sitrep()
sitrep()
Sys.info()
R.Version$version.string
R.Version()
R.Version()$version.string
utils::osVersion
pkgdown::build_site()
install.packages("hexSticker")
install.packages("magick")
getwd()
list.files()
list.files('../../shinyproxy/shinyproxy/')
list.files('../../shinyproxy/shinyproxy/container-logs/logs/')
list.files('../../shinyproxy/shinyproxy/container-logs/logs/')
#' Parse ShinyProxy Log File Name
#'
#' This function parses the name of a log file generated by ShinyProxy and extracts metadata:
#' `specId`, `proxyId`, `startupTime`, and `logType`.
#'
#' @param filename Character. The full path to the log file.
#' @return A data frame with the columns `specId`, `proxyId`, `startupTime`, and `logType`.
#' @examples
#' \dontrun{
#'   parse_log_filename(
#'   "path/to/containersLogs/log_file_(stdout|stderr).log"
#'   )
#' }
#' @export
#' @importFrom stringr str_match
parse_log_filename <- function(filename) {
base_name <- basename(filename)
# Regex pattern to capture:
# - specId: can include underscores (non-greedy match)
# - proxyId: a UUID (e.g., 220c8b25-691d-4922-8c55-3d69bdecb7a0)
# - startupTime: a timestamp in the format 31_Jan_2025_04_02_35
# - logType: either "stdout" or "stderr"
pattern <- "^(.*?)_([0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12})_([0-9]{1,2}_[A-Za-z]{3}_[0-9]{4}_[0-9]{2}_[0-9]{2}_[0-9]{2})_(stdout|stderr)\\.log$"
matches <- stringr::str_match(base_name, pattern)
if (is.na(matches[1, 1])) {
stop(sprintf("The file name '%s' does not match the expected pattern.", filename))
}
data.frame(
specId      = matches[1, 2],
proxyId     = matches[1, 3],
startupTime = matches[1, 4],
logType     = matches[1, 5],
stringsAsFactors = FALSE
)
}
#' Analyze ShinyProxy Log Files in a Directory
#'
#' This function scans a specified directory, extracts metadata from the log file names,
#' reads their content, and computes some statistics (total number of lines and the number of lines
#' containing "error" or "exception"). Additionally, it retrieves ShinyProxy user information from a
#' separate directory of logs.
#'
#' @param path_container_logs Character. The path to the directory containing the container logs files.
#' @param path_shinylogs Character. The path to the directory containing ShinyProxy identity logs.
#' @return A list containing two data frames:
#' \describe{
#'   \item{file_info}{Detailed information for each file.}
#'   \item{summary}{Summary information grouped by container (based on `specId`, `proxyId`, and `startupTime`).}
#' }
#' @export
#' @importFrom dplyr rowwise mutate ungroup select group_by summarise left_join
#' @importFrom purrr map_df
#' @importFrom stringr str_detect regex
#' @examples
#' \dontrun{
#'   result <- analyze_logs("path/to/containersLogs", "path/to/shinylogs")
#'   print(result$summary)
#' }
analyze_logs <- function(path_container_logs, path_shinylogs = NULL) {
# List all files in the path_container_logs with full paths and filter for log files
files <- list.files(path_container_logs, full.names = TRUE)
files <- files[stringr::str_detect(files, "_(stdout|stderr)\\.log$")]
# Extract metadata for each file
file_info <- purrr::map_df(files, function(file) {
info <- parse_log_filename(file)
info$filePath <- file  # store the full path for reading file content later
info
})
# Define regex patterns (case-insensitive) for different log categories:
pattern_error   <- stringr::regex("error|exception", ignore_case = TRUE)
pattern_warning <- stringr::regex("warning", ignore_case = TRUE)
pattern_fatal   <- stringr::regex("fatal", ignore_case = TRUE)
pattern_info    <- stringr::regex("info|debug|started|listening|connected|released", ignore_case = TRUE)
# Read file contents and compute statistics
file_info <- file_info |>
dplyr::rowwise() |>
dplyr::mutate(
content         = list(readLines(filePath, warn = FALSE)),
numLines        = length(content),
numErrorLines   = sum(stringr::str_detect(content, pattern_error)),
numWarningLines = sum(stringr::str_detect(content, pattern_warning)),
numFatalLines   = sum(stringr::str_detect(content, pattern_fatal)),
numInfoLines    = sum(stringr::str_detect(content, pattern_info))
) |>
dplyr::ungroup() |>
dplyr::select(-content)
# Summarize statistics by container (grouping by specId, proxyId, and startupTime)
summary_df <- file_info |>
dplyr::group_by(specId, proxyId, startupTime) |>
dplyr::summarise(
stdout_lines      = sum(numLines[logType == "stdout"], na.rm = TRUE),
stderr_lines      = sum(numLines[logType == "stderr"], na.rm = TRUE),
total_error_lines = sum(numErrorLines, na.rm = TRUE),
total_warning_lines = sum(numWarningLines, na.rm = TRUE),
total_fatal_lines = sum(numFatalLines, na.rm = TRUE),
total_info_lines  = sum(numInfoLines, na.rm = TRUE),
.groups = "drop"
)
# If path_shinylogs is provided, retrieve ShinyProxy users and associated containers
if (!is.null(path_shinylogs)) {
files_identity <- list.files(path_shinylogs, full.names = TRUE)
files_identity <- files_identity[stringr::str_detect(files_identity, "\\.(log|gz)$")]
user_proxy_mapping <- purrr::map_df(files_identity, function(file) {
log_lines <- read_log_file(file)
extract_user_proxy_mapping(log_lines)
})
user_proxy_mapping <- unique(user_proxy_mapping)
summary_df <- summary_df |>
dplyr::left_join(user_proxy_mapping, by = c('proxyId', 'specId')) |>
dplyr::select(specId, proxyId, user, startupTime, stdout_lines, stderr_lines, total_error_lines, total_warning_lines, total_fatal_lines, total_info_lines)
}
list(file_info = file_info, summary = summary_df)
}
#' Read a Log File
#'
#' Internal function to read a log file, supporting both plain text and gzipped formats.
#'
#' @param file Character. The file path to read.
#' @return A character vector of log lines.
#' @keywords internal
read_log_file <- function(file) {
if (grepl("\\.gz$", file)) {
readLines(gzfile(file), warn = FALSE)
} else {
readLines(file, warn = FALSE)
}
}
#' Extract User and Proxy Mappings
#'
#' Internal function to extract user and container mappings from log lines.
#'
#' @param log_lines A character vector containing log file lines.
#' @return A tibble with `user`, `proxyId`, and `specId`.
#' @keywords internal
#' @importFrom tibble tibble
extract_user_proxy_mapping <- function(log_lines) {
pattern <- "\\[user=([^ ]+) proxyId=([^ ]+) specId=([^ ]+)\\]"
matches <- stringr::str_match(log_lines, pattern)
tibble::tibble(
user    = matches[, 2],
proxyId = matches[, 3],
specId  = matches[, 4]
) |>
dplyr::filter(!is.na(user))
}
analyze_logs(path_container_logs = '../../shinyproxy/shinyproxy/container-logs/logs/', path_shinylogs = '../../shinyproxy/shinyproxy/')
install.packages("DBI")
install.packages("RPostgres")
devtools::check()
devtools::check(args = "--as-cran")
devtools::submit_cran()
devtools::submit_cran()
install.packages("httr")
usethis::use_cran_comments()
devtools::submit_cran()
R.version.string
devtools::document()
devtools::check()
devtools::document()
devtools::submit_cran()
devtools::document()
devtools::document()
devtools::check()
devtools::submit_cran()
devtools::check()
Sys.setenv(TZ = "UTC")
devtools::check()
devtools::check()
devtools::document()
devtools::submit_cran()
